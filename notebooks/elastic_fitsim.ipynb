{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from spyral.core.constants import QBRHO_2_P\n",
    "from spyral.core.run_stacks import form_run_string\n",
    "\n",
    "from spyral_utils.nuclear import NuclearDataMap\n",
    "from spyral_utils.nuclear.target import GasTarget, load_target\n",
    "from spyral_utils.plot import Histogrammer\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.constants import physical_constants, torr\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import iqr\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import vector\n",
    "import lmfit\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data config\n",
    "workspace_path = Path(\"D:\\\\e20009_analysis\")\n",
    "target_material_path = Path(\"C:\\\\Users\\\\zachs\\\\Desktop\\\\e20009_analysis\\\\e20009_analysis\\\\e20009_parameters\\\\e20009_target.json\")\n",
    "\n",
    "solver_result_path = workspace_path / \"InterpSolver\"\n",
    "beam_events_path = workspace_path / \"beam_events\"\n",
    "\n",
    "# Run number range (inclusive)\n",
    "run_min = 108\n",
    "run_max = 366\n",
    "\n",
    "# The nucleus we observe (the one fitted)\n",
    "ejectile_z = 1\n",
    "ejectile_a = 2\n",
    "\n",
    "# The incoming nucleus (the beam)\n",
    "projectile_z = 4\n",
    "projectile_a = 10\n",
    "\n",
    "# The target nucleus\n",
    "target_z = 1\n",
    "target_a = 2\n",
    "\n",
    "residual_z = target_z + projectile_z - ejectile_z\n",
    "residual_a = target_a + projectile_a - ejectile_a\n",
    "\n",
    "if residual_z < 0:\n",
    "    raise Exception(f\"Illegal nuclei! Residual Z: {residual_z}\")\n",
    "if residual_a < 1:\n",
    "    raise Exception(f\"Illegal nuclei! Residual A: {residual_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup nuclear data objects\n",
    "nuclear_map = NuclearDataMap()\n",
    "\n",
    "target_material = load_target(target_material_path, nuclear_map)\n",
    "if not isinstance(target_material, GasTarget):\n",
    "    print('Target error!')\n",
    "\n",
    "ejectile = nuclear_map.get_data(ejectile_z, ejectile_a)\n",
    "projectile = nuclear_map.get_data(projectile_z, projectile_a)\n",
    "target = nuclear_map.get_data(target_z, target_a)\n",
    "residual = nuclear_map.get_data(residual_z, residual_a)\n",
    "print(f\"Reaction: {target}({projectile}, {ejectile}){residual}\")\n",
    "print(f\"Target material: {target_material.ugly_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters used for analysis\n",
    "\n",
    "proj_energy_start = 93.1        # Units of MeV. Initial beam energy\n",
    "\n",
    "min_z = 0.004    # Units of meters. Minimum z value of vertex (inclusive)\n",
    "max_z = 0.958    # Units of meters. Maximum z value of vertex (inclusive)\n",
    "\n",
    "min_cm = 18.0    # Units of degrees. Minimum center-of-mass scattering angle for events in excitation spectrum (inclusive)\n",
    "max_cm = 60.0   # Units of degrees. Maximum center-of-mass scattering angle for events in excitation spectrum (inclusive)\n",
    "\n",
    "hist_en_min = -2.0        # Smallest allowed excitation energy in histogram (inclusive)\n",
    "hist_en_max = 5.25    # Largest allowed excitation energy in histogram (inclusive)\n",
    "hist_en_bins = 137        # Number of bins in excitation energy histogram\n",
    "\n",
    "ang_dist_bins = 21     # Number of bins in angular distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters used for finding the cross section\n",
    "\n",
    "downscale_factor = 1000\n",
    "\n",
    "ic_min_val = 300.0\n",
    "ic_max_val = 850.0\n",
    "\n",
    "boltzmann = physical_constants[\"Boltzmann constant\"][0]    # Units of Joules / Kelvin\n",
    "torr_2_pascal = torr    # Convert from torr to pascals\n",
    "pressure = 600 # Units of torr\n",
    "temperature = 273.15    # Units of Kelvin, STP\n",
    "stoich = 2 # Stoichiometry of gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary containing state specific parameters\n",
    "\n",
    "states = {}\n",
    "states[\"gs\"] = {\"peak_num\": 1,\n",
    "                \"sub_min\": -1.0,\n",
    "                \"sub_max\": 1.0,\n",
    "                \"cent_min\": -0.1,\n",
    "                \"cent_max\": 0.6,\n",
    "                \"sim_workspace\": Path(\"E:\\\\final\\\\elastic\\\\workspace\\\\InterpSolver\"),\n",
    "                \"sim_parq\": Path(\"E:\\\\final\\\\elastic\\\\elastic_kine.parquet\"),\n",
    "                \"sim_run_min\": 0,\n",
    "                \"sim_run_max\": 57}\n",
    "\n",
    "states[\"3.37\"] = {\"peak_num\": 2,\n",
    "                \"sub_min\": 2.8,\n",
    "                \"sub_max\": 4.8,\n",
    "                \"cent_min\": 2.8,\n",
    "                \"cent_max\": 4.8,\n",
    "                \"sim_workspace\": Path(\"E:\\\\final\\\\inelastic_3.37\\\\workspace\\\\InterpSolver\"),\n",
    "                \"sim_parq\": Path(\"E:\\\\final\\\\inelastic_3.37\\\\inelastic_3.37_kine.parquet\"),\n",
    "                \"sim_run_min\": 0,\n",
    "                \"sim_run_max\": 57}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose state to analyze\n",
    "\n",
    "state2analyze = \"3.37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store results from analysis\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Add keys for result parameters\n",
    "results[\"polar\"] = np.empty(0, float)\n",
    "results[\"kinetic_energy\"] = np.empty(0, float)\n",
    "results[\"ex_energy\"] = np.empty(0, float)\n",
    "results[\"cm_polar\"] = np.empty(0, float)\n",
    "results[\"chisq\"] = np.empty(0, float)\n",
    "results[\"z_vert\"] = np.empty(0, float)\n",
    "\n",
    "# Create histogram tool\n",
    "grammer = Histogrammer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define line shapes\n",
    "\n",
    "def gaussian(x, amplitude, center, sigma):\n",
    "    model = lmfit.models.GaussianModel()\n",
    "    params = model.make_params(amplitude=amplitude, center=center, sigma=sigma)\n",
    "    return model.eval(params, x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis data\n",
    "\n",
    "target_vector = vector.array({\"px\": [0.0], \"py\": [0.0], \"pz\": [0.0], \"E\": [target.mass]})\n",
    "for run in range(run_min, run_max+1):\n",
    "    df = None\n",
    "    path = solver_result_path / f\"run_{run:04d}_{ejectile.isotopic_symbol}.parquet\"\n",
    "    if not path.exists():\n",
    "        continue\n",
    "    df = pl.scan_parquet(path)\n",
    "\n",
    "    #Apply gates to data\n",
    "    df = (df.filter((pl.col(\"vertex_z\") >= min_z) \n",
    "                   & (pl.col(\"vertex_z\") <= max_z)\n",
    "                   )\n",
    "            .collect()\n",
    "    )\n",
    "\n",
    "    # Construct the projectile vectors (beam)\n",
    "    vertices = df.select(['vertex_x', 'vertex_y', 'vertex_z']).to_numpy()\n",
    "    distances = np.linalg.norm(vertices, axis=1)\n",
    "    projectile_ke = proj_energy_start - target_material.get_energy_loss(projectile, proj_energy_start, distances)\n",
    "    projectile_vector = vector.array({\n",
    "        \"px\": np.zeros(len(projectile_ke)),\n",
    "        \"py\": np.zeros(len(projectile_ke)),\n",
    "        \"pz\": np.sqrt(projectile_ke * (projectile_ke + 2.0 * projectile.mass)),\n",
    "        \"E\": projectile_ke + projectile.mass\n",
    "    })\n",
    "\n",
    "    # Construct the ejectile vectors (detected)\n",
    "    brho = df.select('brho').to_numpy().flatten()\n",
    "    momentum = df.select('brho').to_numpy().flatten() * float(ejectile.Z) * QBRHO_2_P\n",
    "    kinetic_energy = np.sqrt(momentum**2.0 + ejectile.mass**2.0) - ejectile.mass\n",
    "    polar = df.select('polar').to_numpy().flatten()\n",
    "    az = df.select('azimuthal').to_numpy().flatten()\n",
    "    ejectile_vector = vector.array({\n",
    "        \"px\": momentum * np.sin(polar) * np.cos(az),\n",
    "        \"py\": momentum * np.sin(polar) * np.sin(az),\n",
    "        \"pz\": momentum * np.cos(polar),\n",
    "        \"E\": np.sqrt(momentum**2.0 + ejectile.mass**2.0)\n",
    "    })\n",
    "\n",
    "    # Get reduced chi-squared information\n",
    "    cs = df.select('redchisq').to_numpy().flatten()\n",
    "\n",
    "    # Get vertex z position\n",
    "    zvert=df.select('vertex_z').to_numpy().flatten()\n",
    "\n",
    "    # Do the kinematics\n",
    "    residual_vector = target_vector + projectile_vector - ejectile_vector # type: ignore\n",
    "    ex_energy = residual_vector.mass - residual.mass # Excitation energy is \"extra\" mass\n",
    "\n",
    "    # Calculate CM scattering angle \n",
    "    cm_vec = ejectile_vector.boostCM_of(projectile_vector + target_vector)\n",
    "    cm_polar = np.pi - cm_vec.theta\n",
    "\n",
    "    # Fill histograms and arrays\n",
    "    results[\"polar\"] = np.append(results[\"polar\"], polar)\n",
    "    results[\"kinetic_energy\"] = np.append(results[\"kinetic_energy\"], kinetic_energy)\n",
    "    results[\"ex_energy\"] = np.append(results[\"ex_energy\"], ex_energy)\n",
    "    results[\"cm_polar\"] = np.append(results[\"cm_polar\"], cm_polar)\n",
    "    results[\"chisq\"] = np.append(results[\"chisq\"], cs)\n",
    "    results[\"z_vert\"] = np.append(results[\"z_vert\"], zvert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vertex z-ccordinate histogram\n",
    "\n",
    "grammer.add_hist1d('z_vert', 1200, (-0.1, 1.1))\n",
    "grammer.fill_hist1d('z_vert', results[\"z_vert\"])\n",
    "vertz = grammer.get_hist1d(\"z_vert\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(vertz.counts, edges=vertz.bins)\n",
    "ax.set_title(f\"Vertex z-coordinate histogram\")\n",
    "ax.set_xlabel(\"z-coordinate of vertex (m)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform analysis of beam events\n",
    "\n",
    "grammer.add_hist1d('beam_events_ic', 4095, (0.0, 4095.0))\n",
    "\n",
    "for run in range(run_min, run_max+1):\n",
    "    df = None\n",
    "    try:\n",
    "        path = beam_events_path / f\"{form_run_string(run)}.parquet\"\n",
    "        df = pl.read_parquet(path)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    # Apply appropriate analysis gates\n",
    "    df = df.filter((pl.col(\"ic_multiplicity\") == 1)\n",
    "                 & (pl.col(\"ic_sca_multiplicity\") == 1))\n",
    "    df = df.filter((abs(pl.col(\"ic_centroid\").list.get(0) - pl.col(\"ic_sca_centroid\").list.get(0)) <= 10))\n",
    "\n",
    "    ic_amp = df.select(pl.col(\"ic_amplitude\").list.get(0)).to_numpy().flatten()\n",
    "    grammer.fill_hist1d(\"beam_events_ic\", ic_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IC histogram\n",
    "\n",
    "beam_events_ic = grammer.get_hist1d('beam_events_ic')\n",
    "\n",
    "beam_nuc1 = lmfit.models.GaussianModel(prefix=\"beam_nuc1_\")\n",
    "beam_nuc1_bins, beam_nuc1_counts = beam_events_ic.get_subrange((ic_min_val, ic_max_val))\n",
    "beam_nuc1_bins += 0.5 * beam_events_ic.bin_width\n",
    "beam_nuc1_weights = np.sqrt(beam_nuc1_counts)\n",
    "beam_nuc1_weights = np.divide(1, beam_nuc1_weights, out=np.zeros_like(beam_nuc1_weights), where=beam_nuc1_weights!=0.0)\n",
    "pars = beam_nuc1.guess(x=beam_nuc1_bins, data=beam_nuc1_counts, weights=beam_nuc1_weights)\n",
    "pars[\"beam_nuc1_amplitude\"].min = 0.0\n",
    "\n",
    "beam_nuc2 = lmfit.models.GaussianModel(prefix=\"beam_nuc2_\")\n",
    "beam_nuc2_bins, beam_nuc2_counts = beam_events_ic.get_subrange((ic_max_val, 1500))\n",
    "beam_nuc2_weights = np.sqrt(beam_nuc2_counts)\n",
    "beam_nuc2_weights = np.divide(1, beam_nuc2_weights, out=np.zeros_like(beam_nuc2_weights), where=beam_nuc2_weights!=0.0)\n",
    "pars.update(beam_nuc2.guess(x=beam_nuc2_bins, data=beam_nuc2_counts, weights=beam_nuc2_weights))\n",
    "pars[\"beam_nuc2_amplitude\"].min = 0.0\n",
    "\n",
    "total_fit = beam_nuc1 + beam_nuc2\n",
    "total_bins = beam_events_ic.bins[:-1] + beam_events_ic.bin_width/2\n",
    "total_counts = beam_events_ic.counts\n",
    "total_weights = np.sqrt(total_counts)\n",
    "total_weights = np.divide(1, total_weights, out=np.zeros_like(total_weights), where=total_weights!=0.0)\n",
    "total_result = total_fit.fit(params=pars, x=total_bins, data=total_counts, weights=total_weights)\n",
    "comps = total_result.eval_components()\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(beam_events_ic.counts, edges=beam_events_ic.bins, label=\"Spectrum\")\n",
    "ax.plot(total_bins, total_result.best_fit, label=\"Total Fit\")\n",
    "ax.plot(total_bins, comps[\"beam_nuc1_\"], label=\"beam_nuc1\")\n",
    "ax.plot(total_bins, comps[\"beam_nuc2_\"], label=\"beam_nuc2\")\n",
    "ax.set_title('Amplitude of triggering nucleus in beam events')\n",
    "ax.set_xlabel('Amplitude (ADC units)')\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.legend()\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find counts of beam nucleus\n",
    "\n",
    "# Find number of contamination counts from neighboring nucleus' peak\n",
    "A = total_result.params[\"beam_nuc2_amplitude\"].value\n",
    "mu = total_result.params[\"beam_nuc2_center\"].value\n",
    "sigma = total_result.params[\"beam_nuc2_sigma\"].value\n",
    "\n",
    "contamination = quad(gaussian, ic_min_val, ic_max_val, args=(A, mu, sigma))[0] / beam_events_ic.bin_width\n",
    "\n",
    "# Subtract out contamination from counts\n",
    "beam_counts, _, _ = beam_events_ic.stats_for_range((ic_min_val, ic_max_val))\n",
    "beam_counts -= contamination\n",
    "\n",
    "# Multiply by downscaler\n",
    "beam_counts *= downscale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate kinematics for residual particle in given states\n",
    "proj_energy_stop = proj_energy_start - target_material.get_energy_loss(projectile, proj_energy_start, np.array([1.0]))[0] # Energy at far end of detector\n",
    "print(f\"Beam energy range: {proj_energy_start}-{proj_energy_stop} MeV\")\n",
    "residual_excitations = np.array([0.0])\n",
    "\n",
    "# Do the calculation in the center of mass\n",
    "cm_angle_range = np.linspace(0., np.pi, 1000)\n",
    "# Calculate envelope from range of beam energies\n",
    "eject_kinematics = np.zeros((len(residual_excitations), len(cm_angle_range) * 2, 2))\n",
    "\n",
    "# Upper limit (maximum beam energy)\n",
    "beam_vec_max = vector.array({\n",
    "    \"px\": [0.0],\n",
    "    \"py\": [0.0],\n",
    "    \"pz\": [np.sqrt(proj_energy_start * (proj_energy_start + 2.0 * projectile.mass))],\n",
    "    \"E\": [proj_energy_start + projectile.mass]\n",
    "})\n",
    "parent_max = target_vector + beam_vec_max\n",
    "parent_cm_max = parent_max.boostCM_of(parent_max)\n",
    "for idx, ex in enumerate(residual_excitations):\n",
    "    eject_e_cm_max = (ejectile.mass**2.0 - (residual.mass + ex)**2.0 + parent_cm_max.E**2.0) / (2.0 * parent_cm_max.E)\n",
    "    eject_p_cm_max = np.sqrt(eject_e_cm_max**2.0 - ejectile.mass**2.0)\n",
    "    eject_vec_cms_max = vector.array({\n",
    "        \"px\": eject_p_cm_max * np.sin(cm_angle_range),\n",
    "        \"py\": np.zeros(len(cm_angle_range)),\n",
    "        \"pz\": eject_p_cm_max * np.cos(cm_angle_range),\n",
    "        \"E\": np.full(len(cm_angle_range), eject_e_cm_max)\n",
    "    })\n",
    "    eject_vec_lab_max = eject_vec_cms_max.boost(parent_max)\n",
    "    eject_kinematics[idx, :len(cm_angle_range), 0] = eject_vec_lab_max.theta\n",
    "    eject_kinematics[idx, :len(cm_angle_range), 1] = eject_vec_lab_max.E - ejectile.mass\n",
    "\n",
    "# Lower limit (minimum beam energy)\n",
    "beam_vec_min = vector.array({\n",
    "    \"px\": [0.0],\n",
    "    \"py\": [0.0],\n",
    "    \"pz\": [np.sqrt(proj_energy_stop * (proj_energy_stop + 2.0 * projectile.mass))],\n",
    "    \"E\": [proj_energy_stop + projectile.mass]\n",
    "})\n",
    "parent_min = target_vector + beam_vec_min\n",
    "parent_cm_min = parent_min.boostCM_of(parent_min)\n",
    "for idx, ex in enumerate(residual_excitations):\n",
    "    eject_e_cm_min = (ejectile.mass**2.0 - (residual.mass + ex)**2.0 + parent_cm_min.E**2.0) / (2.0 * parent_cm_min.E)\n",
    "    eject_p_cm_min = np.sqrt(eject_e_cm_min**2.0 - ejectile.mass**2.0)\n",
    "    eject_vec_cms_min = vector.array({\n",
    "        \"px\": eject_p_cm_min * np.sin(cm_angle_range),\n",
    "        \"py\": np.zeros(len(cm_angle_range)),\n",
    "        \"pz\": eject_p_cm_min * np.cos(cm_angle_range),\n",
    "        \"E\": np.full(len(cm_angle_range), eject_e_cm_min)\n",
    "    })\n",
    "    eject_vec_lab_min = eject_vec_cms_min.boost(parent_min)\n",
    "    # Note that lower limit is \"flipped\". We plot the band as a polygon, so need to continue from large lab angles to small lab angles\n",
    "    eject_kinematics[idx, len(cm_angle_range):, 0] = np.flip(eject_vec_lab_min.theta)\n",
    "    eject_kinematics[idx, len(cm_angle_range):, 1] = np.flip(eject_vec_lab_min.E - ejectile.mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot kinematics from data and compare with theoretical kinematics\n",
    "grammer.add_hist2d('ke_theta', (500, 1600), ((0.0, 180.0), (0.0, 80.0)))\n",
    "grammer.fill_hist2d('ke_theta', np.rad2deg(results[\"polar\"]), results[\"kinetic_energy\"])\n",
    "ke_theta = grammer.get_hist2d(\"ke_theta\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "mesh = ax.pcolormesh(ke_theta.x_bins, ke_theta.y_bins, ke_theta.counts, norm=\"log\")\n",
    "ax.set_title(\"Kinetic Energy vs. Polar Angle\")\n",
    "ax.set_xlabel(r\"$\\theta$ (deg)\")\n",
    "ax.set_ylabel(\"Kinetic Energy (MeV)\")\n",
    "fig.colorbar(mesh, ax=ax)\n",
    "for idx, ex in enumerate(residual_excitations):\n",
    "    ax.plot(np.rad2deg(eject_kinematics[idx, :len(cm_angle_range), 0]), eject_kinematics[idx, :len(cm_angle_range), 1], label=f\"Ex={ex:02} AT-TPC window\")\n",
    "    # Fill idea thanks to D. Ramirez\n",
    "    ax.fill(np.rad2deg(eject_kinematics[idx, :, 0]), eject_kinematics[idx, :, 1], label=f\"Ex={ex:02} Band\", alpha=0.2)\n",
    "ax.legend()\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced chi-squared of fits to data\n",
    "\n",
    "grammer.add_hist1d('chisq', 2000, (0.0, 1e-4))\n",
    "grammer.fill_hist1d(\"chisq\", results[\"chisq\"])\n",
    "hist = grammer.get_hist1d(\"chisq\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(hist.counts, edges=hist.bins)\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Error\")\n",
    "ax.set_xlabel(\"Error\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot excitation energy spectrum\n",
    "\n",
    "# Gate excitation spectrum on CM angle\n",
    "mask_cm = (np.deg2rad(min_cm) <= results[\"cm_polar\"]) & (results[\"cm_polar\"] <= np.deg2rad(max_cm))    # Make note of inequalites for binning!\n",
    "ex_energy_gated = results[\"ex_energy\"][mask_cm]\n",
    "\n",
    "grammer.add_hist1d(\"ex_energy\",hist_en_bins, (hist_en_min, hist_en_max))\n",
    "grammer.fill_hist1d(\"ex_energy\", ex_energy_gated)\n",
    "\n",
    "ex_hist = grammer.get_hist1d(\"ex_energy\")\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(ex_hist.counts, edges=ex_hist.bins)\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Spectrum, {min_cm}\\N{DEGREE SIGN}-{max_cm}\\N{DEGREE SIGN} c.m.\")\n",
    "ax.set_xlabel(\"Excitation Energy (MeV)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"C:\\\\Users\\\\zachs\\\\Desktop\\\\transfer_ex_spect.csv\", ex_energy_gated, newline=\"\\n\", fmt=\"%.4f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit excitation spectrum peaks for each angular bin\n",
    "\n",
    "# Create dictionary to store results of excitation background removal\n",
    "sub_fits = {}\n",
    "\n",
    "# Make array of edges of angular cuts\n",
    "ang_bins = np.linspace(min_cm, max_cm, ang_dist_bins+1)\n",
    "\n",
    "for idx in range(len(ang_bins) - 1):\n",
    "    low_edge = ang_bins[idx]\n",
    "    high_edge = ang_bins[idx+1]\n",
    "\n",
    "    # Gate excitation spectrum on CM angle\n",
    "    if idx != (len(ang_bins) - 1):\n",
    "        mask = (np.deg2rad(low_edge) <= results[\"cm_polar\"]) & (results[\"cm_polar\"] < np.deg2rad(high_edge))    # Make note of inequalites for binning!\n",
    "    else:\n",
    "        mask = (np.deg2rad(low_edge) <= results[\"cm_polar\"]) & (results[\"cm_polar\"] <= np.deg2rad(high_edge))    # Make note of inequalites for binning!\n",
    "\n",
    "    ex_energy_gated = results[\"ex_energy\"][mask]\n",
    "\n",
    "    # Make and fill histogram\n",
    "    title = f\"ex_energy_{low_edge}-{high_edge}\"\n",
    "    grammer.add_hist1d(title, hist_en_bins, (hist_en_min, hist_en_max))\n",
    "    grammer.fill_hist1d(title, ex_energy_gated)\n",
    "    sub_ex_hist = grammer.get_hist1d(title)\n",
    "\n",
    "    # Fit histogram\n",
    "    peak1 = lmfit.models.GaussianModel(prefix=\"peak1_\")\n",
    "    peak1_bins, peak1_counts = sub_ex_hist.get_subrange((states[\"gs\"][\"sub_min\"], states[\"gs\"][\"sub_max\"]))\n",
    "    peak1_bins += 0.5 * sub_ex_hist.bin_width\n",
    "    peak1_weights = np.sqrt(peak1_counts)\n",
    "    peak1_weights = np.divide(1, peak1_weights, out=np.zeros_like(peak1_weights), where=peak1_weights!=0.0)\n",
    "    pars = peak1.guess(x=peak1_bins, data=peak1_counts, weights=peak1_weights)\n",
    "    pars[\"peak1_amplitude\"].min = 0.0\n",
    "    pars[\"peak1_center\"].min = states[\"gs\"][\"cent_min\"]\n",
    "    pars[\"peak1_center\"].max = states[\"gs\"][\"cent_max\"]\n",
    "\n",
    "    peak2 = lmfit.models.GaussianModel(prefix=\"peak2_\")\n",
    "    peak2_bins, peak2_counts = sub_ex_hist.get_subrange((states[\"3.37\"][\"sub_min\"], states[\"3.37\"][\"sub_max\"]))\n",
    "    peak2_bins += 0.5 * sub_ex_hist.bin_width\n",
    "    peak2_weights = np.sqrt(peak2_counts)\n",
    "    peak2_weights = np.divide(1, peak2_weights, out=np.zeros_like(peak2_weights), where=peak2_weights!=0.0)\n",
    "    pars.update(peak2.guess(x=peak2_bins, data=peak2_counts, weights=peak2_weights))\n",
    "    pars[\"peak2_amplitude\"].min = 0.0\n",
    "    pars[\"peak2_center\"].min = states[\"3.37\"][\"cent_min\"]\n",
    "    pars[\"peak2_center\"].max = states[\"3.37\"][\"cent_max\"]\n",
    "    pars[\"peak1_sigma\"].set(expr=\"peak2_sigma\", vary=False)\n",
    "\n",
    "    total_fit = peak1 + peak2\n",
    "    total_bins = sub_ex_hist.bins[:-1] + sub_ex_hist.bin_width/2\n",
    "    total_counts = sub_ex_hist.counts\n",
    "    total_weights = np.sqrt(total_counts)\n",
    "    total_weights = np.divide(1, total_weights, out=np.zeros_like(total_weights), where=total_weights!=0.0)\n",
    "    total_result = total_fit.fit(params=pars, x=total_bins, data=total_counts, weights=total_weights)\n",
    "\n",
    "    # Store total fit result\n",
    "    sub_fits[title] = total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for checking fit results\n",
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results of the fits\n",
    "\n",
    "idx += 1\n",
    "low_edge = ang_bins[idx]\n",
    "high_edge = ang_bins[idx+1]\n",
    "title = f\"ex_energy_{low_edge}-{high_edge}\"\n",
    "\n",
    "# Get results of fit\n",
    "sub_fit_result = sub_fits[title]\n",
    "comps = sub_fit_result.eval_components()\n",
    "\n",
    "# Plot result\n",
    "fig, ax = plt.subplots(1,1)\n",
    "sub_ex_hist = grammer.get_hist1d(title)\n",
    "ax.stairs(sub_ex_hist.counts, edges=sub_ex_hist.bins, label=\"Spectrum\")\n",
    "ax.plot(total_bins, sub_fit_result.best_fit, label=\"Total Fit\")\n",
    "ax.plot(total_bins, comps[\"peak1_\"], label=\"peak1\")\n",
    "ax.plot(total_bins, comps[\"peak2_\"], label=\"peak2\")\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Spectrum, {low_edge}\\N{DEGREE SIGN}-{high_edge}\\N{DEGREE SIGN} c.m.\")\n",
    "ax.set_xlabel(\"Excitation Energy (MeV)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.legend()\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency factors\n",
    "\n",
    "# Parameters\n",
    "eff_sim_events_path = states[state2analyze][\"sim_workspace\"]\n",
    "kine_path = states[state2analyze][\"sim_parq\"]\n",
    "run_min_eff = states[state2analyze][\"sim_run_min\"]\n",
    "run_max_eff = states[state2analyze][\"sim_run_max\"]\n",
    "\n",
    "# Store results\n",
    "results_eff = {}\n",
    "results_eff[\"cm_polar\"] = np.empty(0, float)\n",
    "results_eff[\"ex_energy\"] = np.empty(0, float)\n",
    "results_eff[\"event\"] = np.empty(0, int)\n",
    "results_eff[\"chisq\"] = np.empty(0, float)\n",
    "\n",
    "for run in range(run_min_eff, run_max_eff+1):\n",
    "    df = None\n",
    "    path = eff_sim_events_path / f\"run_{run:04d}_{ejectile.isotopic_symbol}.parquet\"\n",
    "    if not path.exists():\n",
    "        print(f\"Run {run} does have a solver file!\")\n",
    "        continue\n",
    "    df = pl.scan_parquet(path)\n",
    "\n",
    "    #Apply gates to data\n",
    "    df = (df.filter((pl.col(\"vertex_z\") >= min_z) \n",
    "                   & (pl.col(\"vertex_z\") <= max_z)\n",
    "                   )\n",
    "            .collect()\n",
    "    )\n",
    "\n",
    "    # Construct the projectile vectors (beam)\n",
    "    vertices = df.select(['vertex_x', 'vertex_y', 'vertex_z']).to_numpy()\n",
    "    distances = np.linalg.norm(vertices, axis=1)\n",
    "    projectile_ke = proj_energy_start - target_material.get_energy_loss(projectile, proj_energy_start, distances)\n",
    "    projectile_vector = vector.array({\n",
    "        \"px\": np.zeros(len(projectile_ke)),\n",
    "        \"py\": np.zeros(len(projectile_ke)),\n",
    "        \"pz\": np.sqrt(projectile_ke * (projectile_ke + 2.0 * projectile.mass)),\n",
    "        \"E\": projectile_ke + projectile.mass\n",
    "    })\n",
    "\n",
    "    # Construct the ejectile vectors (detected)\n",
    "    brho = df.select('brho').to_numpy().flatten()\n",
    "    momentum = df.select('brho').to_numpy().flatten() * float(ejectile.Z) * QBRHO_2_P\n",
    "    kinetic_energy = np.sqrt(momentum**2.0 + ejectile.mass**2.0) - ejectile.mass\n",
    "    polar = df.select('polar').to_numpy().flatten()\n",
    "    az = df.select('azimuthal').to_numpy().flatten()\n",
    "    ejectile_vector = vector.array({\n",
    "        \"px\": momentum * np.sin(polar) * np.cos(az),\n",
    "        \"py\": momentum * np.sin(polar) * np.sin(az),\n",
    "        \"pz\": momentum * np.cos(polar),\n",
    "        \"E\": np.sqrt(momentum**2.0 + ejectile.mass**2.0)\n",
    "    })\n",
    "\n",
    "    # Calculate CM scattering angle \n",
    "    cm_vec = ejectile_vector.boostCM_of(projectile_vector + target_vector)\n",
    "    cm_polar = np.pi - cm_vec.theta\n",
    "\n",
    "    # Do the kinematics\n",
    "    residual_vector = target_vector + projectile_vector - ejectile_vector # type: ignore\n",
    "    ex_energy = residual_vector.mass - residual.mass # Excitation energy is \"extra\" mass\n",
    "\n",
    "    # Get reduced chi-squared information\n",
    "    cs = df.select('redchisq').to_numpy().flatten()\n",
    "\n",
    "    # Event number\n",
    "    ev_num = df.select(\"event\").to_numpy()\n",
    "\n",
    "    # Fill array\n",
    "    results_eff[\"cm_polar\"] = np.append(results_eff[\"cm_polar\"], cm_polar)\n",
    "    results_eff[\"ex_energy\"] = np.append(results_eff[\"ex_energy\"], ex_energy)\n",
    "    results_eff[\"event\"] = np.append(results_eff[\"event\"], ev_num)\n",
    "    results_eff[\"chisq\"] = np.append(results_eff[\"chisq\"], cs)\n",
    "\n",
    "\n",
    "# Fit simulated excitation spectrum peak for each angular bin\n",
    "sub_fits_sim = {}\n",
    "for idx in range(len(ang_bins) - 1):\n",
    "    low_edge = ang_bins[idx]\n",
    "    high_edge = ang_bins[idx+1]\n",
    "\n",
    "    # Gate excitation spectrum on CM angle\n",
    "    if idx != (len(ang_bins) - 1):\n",
    "        mask = (np.deg2rad(low_edge) <= results_eff[\"cm_polar\"]) & (results_eff[\"cm_polar\"] < np.deg2rad(high_edge))    # Make note of inequalites for binning!\n",
    "    else:\n",
    "        mask = (np.deg2rad(low_edge) <= results_eff[\"cm_polar\"]) & (results_eff[\"cm_polar\"] <= np.deg2rad(high_edge))    # Make note of inequalites for binning!\n",
    "\n",
    "    ex_energy_gated = results_eff[\"ex_energy\"][mask]\n",
    "\n",
    "    # Make and fill histogram\n",
    "    title = f\"sim_ex_energy_{low_edge}-{high_edge}\"\n",
    "    grammer.add_hist1d(title, hist_en_bins, (hist_en_min, hist_en_max))\n",
    "    grammer.fill_hist1d(title, ex_energy_gated)\n",
    "    sub_ex_hist = grammer.get_hist1d(title)\n",
    "\n",
    "    # Fit histogram\n",
    "    s_peak = lmfit.models.GaussianModel(prefix=\"s_peak_\")\n",
    "    s_peak_bins, s_peak_counts = sub_ex_hist.get_subrange((states[state2analyze][\"sub_min\"], states[state2analyze][\"sub_max\"]))\n",
    "    s_peak_bins += 0.5 * sub_ex_hist.bin_width\n",
    "    s_peak_weights = np.sqrt(s_peak_counts)\n",
    "    s_peak_weights = np.divide(1, s_peak_weights, out=np.zeros_like(s_peak_weights), where=s_peak_weights!=0.0)\n",
    "    s_pars = s_peak.guess(x=s_peak_bins, data=s_peak_counts, weights=s_peak_weights)\n",
    "    s_pars[\"s_peak_amplitude\"].min = 0.0\n",
    "    s_pars[\"s_peak_center\"].min = states[state2analyze][\"cent_min\"]\n",
    "    s_pars[\"s_peak_center\"].max = states[state2analyze][\"cent_max\"]\n",
    "\n",
    "    s_bins = sub_ex_hist.bins[:-1] + sub_ex_hist.bin_width/2\n",
    "    s_counts = sub_ex_hist.counts\n",
    "    s_weights = np.sqrt(s_counts)\n",
    "    s_weights = np.divide(1, s_weights, out=np.zeros_like(s_weights), where=s_weights!=0.0)\n",
    "    s_result = s_peak.fit(params=s_pars, x=s_bins, data=s_counts, weights=s_weights)\n",
    "\n",
    "    # Store total fit result\n",
    "    sub_fits_sim[title] = s_result\n",
    "\n",
    "# Find counts in each angular bin\n",
    "sim_survived = np.zeros(ang_dist_bins, dtype=int)\n",
    "\n",
    "# Use for Gaussian state\n",
    "for idx, fit in enumerate(sub_fits_sim.items()):\n",
    "    amplitude = fit[1].params[\"s_peak_amplitude\"].value\n",
    "    center= fit[1].params[\"s_peak_center\"].value\n",
    "    sigma = fit[1].params[\"s_peak_sigma\"].value\n",
    "    sim_survived[idx] = quad(gaussian, hist_en_min, hist_en_max, args=(amplitude, center, sigma))[0] / ex_hist.bin_width\n",
    "\n",
    "# Histogram of all simulated CM angles from kinematics file\n",
    "kine_f = pl.scan_parquet(kine_path)\n",
    "\n",
    "beam_coords = (\n",
    "    kine_f.gather_every(4, offset=1)\n",
    "    .select(\"px\", \"py\", \"pz\", \"energy\")\n",
    "    .collect()\n",
    "    .to_numpy()\n",
    ")\n",
    "beam_vectors = vector.array(\n",
    "    {\n",
    "        \"px\": beam_coords[:, 0],\n",
    "        \"py\": beam_coords[:, 1],\n",
    "        \"pz\": beam_coords[:, 2],\n",
    "        \"E\": beam_coords[:, 3],\n",
    "    }\n",
    ")\n",
    "product_coords = (\n",
    "    kine_f.gather_every(4, offset=3)\n",
    "    .select(\"px\", \"py\", \"pz\", \"energy\")\n",
    "    .collect()\n",
    "    .to_numpy()\n",
    ")\n",
    "product_vectors = vector.array(\n",
    "    {\n",
    "        \"px\": product_coords[:, 0],\n",
    "        \"py\": product_coords[:, 1],\n",
    "        \"pz\": product_coords[:, 2],\n",
    "        \"E\": product_coords[:, 3],\n",
    "    }\n",
    ")\n",
    "\n",
    "cm_ang_sim_all = product_vectors.boostCM_of(beam_vectors + target_vector).theta\n",
    "grammer.add_hist1d(\"cm_polar_sim_all\", ang_dist_bins, (min_cm, max_cm))\n",
    "grammer.fill_hist1d(\"cm_polar_sim_all\", np.rad2deg(cm_ang_sim_all))\n",
    "sim_all = grammer.get_hist1d(\"cm_polar_sim_all\")\n",
    "\n",
    "# Calculate efficiency factors\n",
    "eff_factors = sim_all.counts/sim_survived\n",
    "eff_factors_err = eff_factors * np.sqrt(1 / sim_all.counts + 1 / sim_survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for checking sim fit results\n",
    "idx_sim = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results of sim fits\n",
    "\n",
    "idx_sim += 1\n",
    "low_edge = ang_bins[idx_sim]\n",
    "high_edge = ang_bins[idx_sim+1]\n",
    "title = f\"sim_ex_energy_{low_edge}-{high_edge}\"\n",
    "\n",
    "# Get results of fit\n",
    "sub_sim = sub_fits_sim[title]\n",
    "comps_sim = sub_sim.eval_components()\n",
    "\n",
    "# Plot result\n",
    "fig, ax = plt.subplots(1,1)\n",
    "sub_ex_hist = grammer.get_hist1d(title)\n",
    "ax.stairs(sub_ex_hist.counts, edges=sub_ex_hist.bins, label=\"Spectrum\")\n",
    "ax.plot(s_bins, comps_sim[\"s_peak_\"], label=\"s_peak_\")\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Simulated Spectrum, {low_edge}\\N{DEGREE SIGN}-{high_edge}\\N{DEGREE SIGN} c.m.\")\n",
    "ax.set_xlabel(\"Excitation Energy (MeV)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.legend()\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find angle error from simulations\n",
    "\n",
    "# Make LazyFrame of all simulated events' cm angle and their event number\n",
    "cm_sim_f = pl.LazyFrame({\"event\": kine_f.gather_every(4).select(\"event\").collect().to_numpy().flatten(), \"cm_angle\": cm_ang_sim_all})\n",
    "\n",
    "# Store angle error\n",
    "cm_err = np.zeros(ang_dist_bins, dtype=float)\n",
    "\n",
    "for idx in range(len(ang_bins) - 1):\n",
    "    low_edge = ang_bins[idx]\n",
    "    high_edge = ang_bins[idx+1]\n",
    "\n",
    "    # Gate excitation spectrum on CM angle\n",
    "    if idx != (len(ang_bins) - 1):\n",
    "        mask_x = (np.deg2rad(low_edge) <= results_eff[\"cm_polar\"]) & (results_eff[\"cm_polar\"] < np.deg2rad(high_edge))    # Make note of inequalites for binning!\n",
    "    else:\n",
    "        mask_x = (np.deg2rad(low_edge) <= results_eff[\"cm_polar\"]) & (results_eff[\"cm_polar\"] <= np.deg2rad(high_edge))    # Make note of inequalites for binning!\n",
    "\n",
    "    # Gate excitation spectrum to only include events with excitation energy in our histogram\n",
    "    mask_y = (hist_en_min <= results_eff[\"ex_energy\"]) & (results_eff[\"ex_energy\"] <= hist_en_max) \n",
    "\n",
    "    # Find events with multiple analyzed tracks\n",
    "    mult_sort, mult_count = np.unique(results_eff[\"event\"][mask_x & mask_y], return_counts=True)\n",
    "\n",
    "    # Add events back in\n",
    "    events_in_bin = np.empty(0, float)\n",
    "    for mult in range(1, np.max(mult_count)+1):\n",
    "        sub_frame = cm_sim_f.filter(pl.col(\"event\").is_in(mult_sort[mult_count==mult]))\n",
    "        sub_frame = pl.concat([sub_frame]*mult)\n",
    "        events_in_bin = np.append(events_in_bin, sub_frame.select(\"cm_angle\").collect().to_numpy().flatten())\n",
    "\n",
    "    cm_err[idx] = np.rad2deg(iqr(events_in_bin))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CM scattering angle histogram\n",
    "\n",
    "cm_counts = np.zeros(ang_dist_bins, dtype=int)\n",
    "\n",
    "state_id = states[state2analyze][\"peak_num\"]\n",
    "# Use for Gaussian states\n",
    "for idx, fit in enumerate(sub_fits.items()):\n",
    "    amplitude = fit[1].params[f\"peak{state_id}_amplitude\"].value\n",
    "    center= fit[1].params[f\"peak{state_id}_center\"].value\n",
    "    sigma = fit[1].params[f\"peak{state_id}_sigma\"].value\n",
    "    cm_counts[idx] = quad(gaussian, hist_en_min, hist_en_max, args=(amplitude, center, sigma))[0] / ex_hist.bin_width\n",
    "\n",
    "grammer.add_hist1d(\"cm_polar\", ang_dist_bins, (min_cm, max_cm))\n",
    "cm_hist = grammer.get_hist1d(\"cm_polar\")\n",
    "cm_hist.counts = cm_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross section\n",
    "\n",
    "length = 1    # Units of meters\n",
    "nuclei_areal_density = pressure * torr_2_pascal * length / boltzmann / temperature * stoich * 1.0e-31 # Units of target nuclei / millibarns\n",
    "\n",
    "# # Without efficiency correction\n",
    "# xs = cm_hist.counts  / np.diff(np.cos(np.deg2rad(cm_hist.bins))) / (-2 * np.pi * beam_counts * nuclei_areal_density)   # Units of millibarns / steradians\n",
    "# xs_err = np.sqrt(cm_hist.counts) / np.diff(np.cos(np.deg2rad(cm_hist.bins))) / (-2 * np.pi * beam_counts * nuclei_areal_density)\n",
    "\n",
    "# With effiency correction\n",
    "xs = cm_hist.counts * eff_factors  / np.diff(np.cos(np.deg2rad(cm_hist.bins))) / (-2 * np.pi * beam_counts * nuclei_areal_density)   # Units of millibarns / steradians\n",
    "xs_err = np.sqrt((eff_factors * np.sqrt(cm_hist.counts))**2 + (cm_hist.counts * eff_factors_err)**2) / np.diff(np.cos(np.deg2rad(cm_hist.bins))) / (-2 * np.pi * beam_counts * nuclei_areal_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot angular distribution\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.errorbar(cm_hist.bins[:-1]+cm_hist.bin_width/2, xs, yerr=xs_err, xerr=cm_err, fmt='o', label=\"This experiment\")\n",
    "\n",
    "#elastic\n",
    "# elastic_an_cai = pl.read_csv(\"C:\\\\Users\\\\zachs\\\\Desktop\\\\elastic_an_cai_93.5.csv\")\n",
    "# elastic_an_cai_d = elastic_an_cai.to_dict(as_series=True)\n",
    "# ax.plot(elastic_an_cai_d['cm_angle'],elastic_an_cai_d['cm_xs'], label=\"An Cai\")\n",
    "\n",
    "ax.set_title(\"Elastic\")\n",
    "ax.set_xlabel(r\"$\\theta_{CM}$ (deg)\")\n",
    "ax.set_ylabel(r\"$d\\sigma / d\\Omega$ (mb / sr)\")\n",
    "ax.legend()\n",
    "plt.xlim(min_cm, max_cm)\n",
    "plt.semilogy()\n",
    "# plt.ylim(1e-1,1e4)\n",
    "# plt.ylim(0,20)\n",
    "# fig.set_figwidth(8.0)\n",
    "# fig.set_figwidth(11.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"C:\\\\Users\\\\zachs\\\\Desktop\\\\elastic_xs.csv\", np.array([cm_hist.bins[:-1]+cm_hist.bin_width/2, cm_err, xs, xs_err]).T, newline=\"\\n\", fmt=\"%.4f\", delimiter=\",\", header=\"ang(deg),ang_err,xs(mb),xs_err\", comments=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e20009_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
